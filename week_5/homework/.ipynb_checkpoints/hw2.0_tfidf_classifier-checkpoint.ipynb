{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - TF-IDF Classifier\n",
    "\n",
    "Ваша цель обучить классификатор который будет находить \"токсичные\" комментарии и опубликовать решения на Kaggle [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
    "\n",
    "В процессе обучения нужно ответить на ***[вопросы](https://docs.google.com/forms/d/e/1FAIpQLSd9mQx8EFpSH6FhCy1M_FmISzy3lhgyyqV3TN0pmtop7slmTA/viewform?usp=sf_link)***\n",
    "\n",
    "Данные можно скачать тут - https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('../data/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../data/test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стадартными подходами для анализа текста являются [Bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model) и его модификация [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).\n",
    "\n",
    "Они реалзованны в `sklearn` в виде [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) и [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "Более подробней про них можно посмотреть [тут](https://github.com/udsclub/workshop/blob/master/notebooks/UDS-workshop-feature-extraction-and-engineering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "# Весь текст\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Какое слово встречается чаще всего в объединенном train и test датасете? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = CountVectorizer()\n",
    "fitted_vect = word_vectorizer.fit_transform(all_text)\n",
    "fitted_words = word_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fitted_vect.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vectorizer.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_words[res.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Увеличение параметра C в Logistic regression увеличивает или уменьшает степень регуляризации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуйте разные Vectorizer и разные размеры n-gramm, стоп-слова, обрезку редких слов, обрезку слишком частых слов\n",
    "# TfidfVectorizer или CountVectorizer\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 1), \n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    min_df=5,\n",
    "    stop_words='english',\n",
    "    binary=True,\n",
    "    max_features=32500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификации будем использовать логистическую регрессию [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем тренировать по одному классификатору на каждый класс. \n",
    "\n",
    "Что бы провалидировать качество модели воспользуемся функцией [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "CV score for class toxic is 0.970806164584013\n",
      "CV score for class severe_toxic is 0.9861952102091196\n",
      "CV score for class obscene is 0.9864176193789476\n",
      "CV score for class threat is 0.984516376410209\n",
      "CV score for class insult is 0.9777242128082898\n",
      "CV score for class identity_hate is 0.9761783602537039\n",
      "Total score is 0.9803063239407138\n"
     ]
    }
   ],
   "source": [
    "scores= []\n",
    "print(class_names)\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, cv=5, scoring='roc_auc'))\n",
    "    \n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    scores.append(cv_score)\n",
    "\n",
    "print('Total score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)\n",
    "# # grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте подобрать лучшие параметры для `word_vectorizer` и `classifier` оптимизируя метрику [ROC AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Log reg for class_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8f4e1f01dca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m classifier_0 = LogisticRegression(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfit_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mintercept_scaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12.35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "classifier_0 = LogisticRegression(\n",
    "    C = 2.4,\n",
    "    class_weight = None,\n",
    "    fit_intercept = True,\n",
    "    intercept_scaling = 12.35,\n",
    "    penalty = 'l2',\n",
    "    tol =  0.001)\n",
    "# 0.9719362659931324"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Log reg for class_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_1 = LogisticRegression(\n",
    "    C = 1.5,\n",
    "    class_weight = None,\n",
    "    fit_intercept = True,\n",
    "    intercept_scaling = 17,\n",
    "    penalty = 'l2',\n",
    "    tol = 0.0007)\n",
    "# 0.986150995403303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Log reg for class_names[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_2 = LogisticRegression(\n",
    "    C = 0.7,\n",
    "    class_weight = 'balanced',\n",
    "    fit_intercept = True,\n",
    "    intercept_scaling = 2.7,\n",
    "    penalty = 'l2',\n",
    "    tol = 0.0008)\n",
    "# 0.9869311642503303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Log reg for class_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_3 = LogisticRegression(\n",
    "    C = 2.2,\n",
    "    class_weight = None,\n",
    "    fit_intercept = True,\n",
    "    intercept_scaling = 15.9,\n",
    "    penalty = 'l2',\n",
    "    tol = 0.015)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Log reg for class_names[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_4 = LogisticRegression(\n",
    "    C = 1,\n",
    "    class_weight = 'balanced',\n",
    "    fit_intercept = True,\n",
    "    intercept_scaling = 2,\n",
    "    penalty = 'l2',\n",
    "    tol = 0.0012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Log reg for class_names[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_5 = LogisticRegression(\n",
    "    C = 1.3,\n",
    "    class_weight = None,\n",
    "    fit_intercept = True,\n",
    "    intercept_scaling = 13.5,\n",
    "    penalty = 'l2',\n",
    "    tol = 0.001)\n",
    "# 0.9759035878959543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores= []\n",
    "\n",
    "# for class_name in class_names:\n",
    "#     train_target = train[class_name]\n",
    "\n",
    "#     cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, cv=5, scoring='roc_auc'))\n",
    "    \n",
    "#     print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "#     scores.append(cv_score)\n",
    "\n",
    "# print('Total score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train\n",
    "\n",
    "# for class_name in class_names:\n",
    "#     train_target = train[class_name]\n",
    "#     classifier.fit(train_word_features, train_target)\n",
    "#     submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опубликуйте лучшие решение на [Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808266582594166\n"
     ]
    }
   ],
   "source": [
    "cv_score_0 = np.mean(cross_val_score(classifier_0, train_word_features, train[class_names[0]], cv=5, scoring='roc_auc'))\n",
    "cv_score_1 = np.mean(cross_val_score(classifier_1, train_word_features, train[class_names[1]], cv=5, scoring='roc_auc'))\n",
    "cv_score_2 = np.mean(cross_val_score(classifier_2, train_word_features, train[class_names[2]], cv=5, scoring='roc_auc'))\n",
    "cv_score_3 = np.mean(cross_val_score(classifier_3, train_word_features, train[class_names[3]], cv=5, scoring='roc_auc'))\n",
    "cv_score_4 = np.mean(cross_val_score(classifier_4, train_word_features, train[class_names[4]], cv=5, scoring='roc_auc'))\n",
    "cv_score_5 = np.mean(cross_val_score(classifier_5, train_word_features, train[class_names[5]], cv=5, scoring='roc_auc'))\n",
    "\n",
    "print(np.mean([cv_score_0, cv_score_1, cv_score_2, cv_score_3, cv_score_4, cv_score_5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_0.fit(train_word_features, train[class_names[0]])\n",
    "classifier_1.fit(train_word_features, train[class_names[1]])\n",
    "classifier_2.fit(train_word_features, train[class_names[2]])\n",
    "classifier_3.fit(train_word_features, train[class_names[3]])\n",
    "classifier_4.fit(train_word_features, train[class_names[4]])\n",
    "classifier_5.fit(train_word_features, train[class_names[5]])\n",
    "\n",
    "submission[class_names[0]] = classifier_0.predict_proba(test_word_features)[:, 1]\n",
    "submission[class_names[1]] = classifier_1.predict_proba(test_word_features)[:, 1]\n",
    "submission[class_names[2]] = classifier_2.predict_proba(test_word_features)[:, 1]\n",
    "submission[class_names[3]] = classifier_3.predict_proba(test_word_features)[:, 1]\n",
    "submission[class_names[4]] = classifier_4.predict_proba(test_word_features)[:, 1]\n",
    "submission[class_names[5]] = classifier_5.predict_proba(test_word_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
